# -- Application Settings --
spring.application.name=user-service
# The internal port must be 8080 to match what the gateway expects
server.port=${SERVER_PORT:8080}

# --- Datasource Configuration (FIXED) ---
# These variables are provided by your docker-compose.yml
spring.datasource.url=${SPRING_DATASOURCE_URL}
spring.datasource.username=${SPRING_DATASOURCE_USERNAME}
spring.datasource.password=${SPRING_DATASOURCE_PASSWORD}
spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.PostgreSQLDialect

# --- Hibernate Properties ---
spring.jpa.hibernate.ddl-auto=update
spring.jpa.show-sql=true

# --- Security & Keycloak Configuration ---
spring.security.oauth2.resourceserver.jwt.issuer-uri=${SPRING_SECURITY_OAUTH2_RESOURCESERVER_JWT_ISSUER_URI}
spring.security.oauth2.resourceserver.jwt.jwk-set-uri=${SPRING_SECURITY_OAUTH2_RESOURCESERVER_JWT_JWK_SET_URI}

# === KAFKA CONSUMER CONFIG (CONFLUENT CLOUD) ===
spring.kafka.consumer.bootstrap-servers=${KAFKA_URL}
spring.kafka.consumer.group-id=user-service-group

# --- Security (SASL_SSL) ---
spring.kafka.consumer.security.protocol=SASL_SSL
spring.kafka.consumer.sasl.mechanism=PLAIN
# This line constructs the username/password from our env variables
spring.kafka.consumer.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="${KAFKA_KEY}" password="${KAFKA_SECRET}";

# --- Deserializers (JSON) ---
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer
# This is more robust than specifying a single package
spring.kafka.consumer.properties.spring.json.trusted.packages=*

# Disables JMX to prevent InstanceAlreadyExistsException on restarts
spring.jmx.enabled=false